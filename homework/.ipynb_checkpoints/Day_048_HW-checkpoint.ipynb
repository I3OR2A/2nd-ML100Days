{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299403</td>\n",
       "      <td>-1.226624</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>-1.176150</td>\n",
       "      <td>5.289853</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>2.404498</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850465</td>\n",
       "      <td>-0.622990</td>\n",
       "      <td>-1.833057</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>3.552681</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>3.305972</td>\n",
       "      <td>-2.715559</td>\n",
       "      <td>-2.682409</td>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
       "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
       "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
       "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
       "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
       "\n",
       "         7         8         9     ...           30        31        32  \\\n",
       "0  1.594506 -0.051608  0.663234    ...    -0.850465 -0.622990 -1.833057   \n",
       "1  2.619246 -0.765884 -0.093780    ...    -0.819750  0.012037  2.038836   \n",
       "2 -4.219054 -1.184919 -1.240310    ...    -0.604501  0.750054 -3.360521   \n",
       "3  4.499666  1.038741 -1.092716    ...     1.022959  1.275598 -3.480110   \n",
       "4 -4.290282 -1.761308  0.807652    ...     0.513906 -1.803473  0.518579   \n",
       "\n",
       "         33        34        35        36        37        38        39  \n",
       "0  0.293024  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
       "1  0.468579 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
       "2  0.856988 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
       "3 -1.065252  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
       "4 -0.205029 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'data/'\n",
    "df = pd.read_csv(data_path + 'train.csv', header=None)\n",
    "df_test = pd.read_csv(data_path + 'test.csv', header=None)\n",
    "\n",
    "train_Y = pd.read_csv(data_path + 'trainLabels.csv', header=None)\n",
    "df.head()\n",
    "# rint(train_Y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  0\n",
       "2  0\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299403</td>\n",
       "      <td>-1.226624</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>-1.176150</td>\n",
       "      <td>5.289853</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>2.404498</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.622990</td>\n",
       "      <td>-1.833057</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>3.552681</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>3.305972</td>\n",
       "      <td>-2.715559</td>\n",
       "      <td>-2.682409</td>\n",
       "      <td>0.101050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
       "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
       "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
       "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
       "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
       "\n",
       "         7         8         9  ...        31        32        33        34  \\\n",
       "0  1.594506 -0.051608  0.663234 ... -0.622990 -1.833057  0.293024  3.552681   \n",
       "1  2.619246 -0.765884 -0.093780 ...  0.012037  2.038836  0.468579 -0.517657   \n",
       "2 -4.219054 -1.184919 -1.240310 ...  0.750054 -3.360521  0.856988 -2.751451   \n",
       "3  4.499666  1.038741 -1.092716 ...  1.275598 -3.480110 -1.065252  2.153133   \n",
       "4 -4.290282 -1.761308  0.807652 ... -1.803473  0.518579 -0.205029 -4.744566   \n",
       "\n",
       "         35        36        37        38        39  40  \n",
       "0  0.717611  3.305972 -2.715559 -2.682409  0.101050   1  \n",
       "1  0.422326  0.803699  1.213219  1.382932 -1.817761   0  \n",
       "2 -1.582735  1.672246  0.656438 -0.932473  2.987436   0  \n",
       "3  1.563539  2.767117  0.215748  0.619645  1.883397   1  \n",
       "4 -1.520015  1.830651  0.870772 -1.894609  0.408332   0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, train_Y], axis = 1, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X shape:  (1000, 41)\n",
      "Test X shape:  (9000, 40)\n",
      "Train Y shape:  (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train X shape: \", df.shape)\n",
    "print(\"Test X shape: \", df_test.shape)\n",
    "print(\"Train Y shape: \", train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 計算df整體相關係數, 並繪製成熱圖\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Numeric Features : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299403</td>\n",
       "      <td>-1.226624</td>\n",
       "      <td>1.498425</td>\n",
       "      <td>-1.176150</td>\n",
       "      <td>5.289853</td>\n",
       "      <td>0.208297</td>\n",
       "      <td>2.404498</td>\n",
       "      <td>1.594506</td>\n",
       "      <td>-0.051608</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.850465</td>\n",
       "      <td>-0.622990</td>\n",
       "      <td>-1.833057</td>\n",
       "      <td>0.293024</td>\n",
       "      <td>3.552681</td>\n",
       "      <td>0.717611</td>\n",
       "      <td>3.305972</td>\n",
       "      <td>-2.715559</td>\n",
       "      <td>-2.682409</td>\n",
       "      <td>0.101050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
       "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
       "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
       "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
       "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
       "\n",
       "         7         8         9     ...           30        31        32  \\\n",
       "0  1.594506 -0.051608  0.663234    ...    -0.850465 -0.622990 -1.833057   \n",
       "1  2.619246 -0.765884 -0.093780    ...    -0.819750  0.012037  2.038836   \n",
       "2 -4.219054 -1.184919 -1.240310    ...    -0.604501  0.750054 -3.360521   \n",
       "3  4.499666  1.038741 -1.092716    ...     1.022959  1.275598 -3.480110   \n",
       "4 -4.290282 -1.761308  0.807652    ...     0.513906 -1.803473  0.518579   \n",
       "\n",
       "         33        34        35        36        37        38        39  \n",
       "0  0.293024  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
       "1  0.468579 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
       "2  0.856988 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
       "3 -1.065252  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
       "4 -0.205029 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 記得刪除 train_Y\n",
    "df = df.drop([df.index[40]] , axis=1)\n",
    "\n",
    "num_features = []\n",
    "for dtype, feature in zip(df.dtypes, df.columns):\n",
    "    if dtype == 'float64' or dtype == 'int64':\n",
    "        num_features.append(feature)\n",
    "print(f'{len(num_features)} Numeric Features : {num_features}\\n')\n",
    "\n",
    "# 削減文字型欄位, 只剩數值型欄位\n",
    "df = df.fillna(-1)\n",
    "MMEncoder = MinMaxScaler()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 41)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(corr.shape)\n",
    "print(type(corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "[4, 6, 12, 14, 18, 23, 28, 32, 34, 36, 39]\n"
     ]
    }
   ],
   "source": [
    "# 篩選相關係數大於 0.1 或小於 -0.1 的特徵\n",
    "high_list = list(corr[(corr[df.index[40]]>0.1) | (corr[df.index[40]]<-0.1)].index)\n",
    "print(high_list.pop(-1))\n",
    "print(high_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42645316827025076"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原始特徵 + 線性迴歸\n",
    "train_X = MMEncoder.fit_transform(df)\n",
    "estimator = LinearRegression()\n",
    "cross_val_score(estimator, train_X, train_Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4326965801622801"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 高相關性特徵 + 線性迴歸\n",
    "train_X = MMEncoder.fit_transform(df[high_list])\n",
    "cross_val_score(estimator, train_X, train_Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5753987612408602"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原始特徵 + 梯度提升樹\n",
    "train_X = MMEncoder.fit_transform(df)\n",
    "estimator = GradientBoostingRegressor()\n",
    "cross_val_score(estimator, train_X, train_Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5813509018865123"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 高相關性特徵 + 梯度提升樹\n",
    "train_X = MMEncoder.fit_transform(df[high_list])\n",
    "cross_val_score(estimator, train_X, train_Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01572355, -0.00977437, -0.00340718,  0.03004963,  0.70689156,\n",
       "       -0.        , -0.        ,  0.03843697,  0.        ,  0.13041342,\n",
       "       -0.00316024, -0.        ,  0.73375227,  0.04708709,  0.80293863,\n",
       "       -0.08884015,  0.01764053, -0.03531876,  0.11668808,  0.0351897 ,\n",
       "       -0.04784556, -0.06997287,  0.        ,  0.        ,  0.        ,\n",
       "       -0.05259969,  0.09855996, -0.04722941, -0.        , -0.02684232,\n",
       "       -0.01519524, -0.        , -0.21854417, -0.11740556,  0.50685131,\n",
       "        0.        , -0.42530934,  0.10047544, -0.18659154,  0.93117192])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "L1_Reg = Lasso(alpha=0.001)\n",
    "train_X = MMEncoder.fit_transform(df)\n",
    "L1_Reg.fit(train_X, train_Y)\n",
    "L1_Reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  7,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "            21, 25, 26, 27, 29, 30, 32, 33, 34, 36, 37, 38, 39],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1_mask = list((L1_Reg.coef_>0) | (L1_Reg.coef_<0))\n",
    "df.columns[L1_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 29,\n",
       " 30,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import compress\n",
    "L1_mask = list((L1_Reg.coef_>0) | (L1_Reg.coef_<0))\n",
    "L1_list = list(compress(list(df), list(L1_mask)))\n",
    "L1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43458072431215367"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1_Embedding 特徵 + 線性迴歸\n",
    "train_X = MMEncoder.fit_transform(df[L1_list])\n",
    "estimator = LinearRegression()\n",
    "cross_val_score(estimator, train_X, train_Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5592504680394303"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1_Embedding 特徵 + 梯度提升樹\n",
    "train_X = MMEncoder.fit_transform(df[L1_list])\n",
    "estimator = GradientBoostingRegressor()\n",
    "cross_val_score(estimator, train_X, train_Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_X, train_Y.values.ravel(), test_size=0.25, random_state=4)\n",
    "\n",
    "\n",
    "# 建立模型 (使用 100 顆樹，每棵樹的最大深度為 10)\n",
    "clr = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "\n",
    "# 訓練模型\n",
    "clr.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = clr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  1.0\n",
      "Test Accuracy:  0.876\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \", clr.score(x_train, y_train))\n",
    "print(\"Test Accuracy: \", clr.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = MMEncoder.fit_transform(df_test[L1_list])\n",
    "test_Y_pred = clr.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 儲存預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算提交結果\n",
    "submit = app_test['Id']\n",
    "print(type(submit)) # --> 會是一個Series\n",
    "submit = app_test[['SK_ID_CURR']]\n",
    "print(type(submit)) # --> 會是一個Dataframe\n",
    "submit['Solution'] = test_Y_pred\n",
    "\n",
    "submit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
